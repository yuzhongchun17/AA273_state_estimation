{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Bundle Adjustment SLAM in 2D\n",
        "\n",
        "STUDENT VERSION.\n",
        "\n",
        "Students: Please go to `File > Save a copy in Drive` before proceeding."
      ],
      "metadata": {
        "id": "Lm8coObm7Pik"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXwUXYws66Yi"
      },
      "outputs": [],
      "source": [
        "# First, install gtsam\n",
        "!pip install gtsam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import standard packages\n",
        "# For vectorized operations and linear algebra\n",
        "import numpy as np\n",
        "# For plotting\n",
        "import matplotlib.pyplot as plt\n",
        "# For loading in the CSV data as a proper table (i.e., dataframe)\n",
        "import pandas as pd\n",
        "\n",
        "# Import the key packages for gtsam\n",
        "# The top level package\n",
        "import gtsam\n",
        "# As implied, the plotting tools\n",
        "import gtsam.utils.plot as gtsam_plot\n",
        "# Convenience methods for landmarks (L) and states (X)\n",
        "# These need to be reset if defined later\n",
        "from gtsam.symbol_shorthand import L, X"
      ],
      "metadata": {
        "id": "v-8eQH9W9Z1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to load in the data. Click the folder icon at left. This is your directory. Drag the `robot_history_{num}.csv` files into the panel that appears. You will have to repeat this if you restart the Google Colab session."
      ],
      "metadata": {
        "id": "FcU9sh_w-Hhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the data as a table\n",
        "\n",
        "# You will come back to change this at the end\n",
        "### TODO (Q4.b and Q4.g) ###\n",
        "robot_gt_df = pd.read_csv('robot_history_5.csv') # this is GROUND TRUTH (gt)!\n",
        "###\n",
        "\n",
        "# Data is (time), (x, y, theta), (speed, dtheta), (measurements)\n",
        "n_time_steps, n_params = robot_gt_df.shape\n",
        "n_landmarks = (n_params - (1 + 3 + 2)) // 2\n",
        "\n",
        "print(f\"Data contains {n_time_steps} time steps and {n_landmarks} landmarks.\\n\")\n",
        "robot_gt_df"
      ],
      "metadata": {
        "id": "bMWQrkm8-HH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding noise\n",
        "\n",
        "The data provided is ground truth. The code below adds the required noise. You can change these, but you should put everything back to the original settings when you submit"
      ],
      "metadata": {
        "id": "bK2affyG_nyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Code to roll out the trajectory\n",
        "\n",
        "def step_robot_pose(pose_curr: np.ndarray, speed: float, delta_theta: float):\n",
        "    \"\"\"\n",
        "    Take the speed and turn to update the 2D pose.\n",
        "    \"\"\"\n",
        "    # Unpack the pose\n",
        "    x, y, theta = pose_curr\n",
        "\n",
        "    # Update the position\n",
        "    x += speed * np.cos(theta)\n",
        "    y += speed * np.sin(theta)\n",
        "\n",
        "    # Update the angle at the END of the step\n",
        "    theta += delta_theta\n",
        "\n",
        "    # Wrap the angle to [-pi, pi]\n",
        "    theta = (theta + np.pi) % (2 * np.pi) - np.pi\n",
        "\n",
        "    # Pack the pose back up\n",
        "    return np.array([x, y, theta])\n",
        "\n",
        "def rollout_robot_pose(pose_start: np.ndarray,\n",
        "                       speeds: np.ndarray,\n",
        "                       delta_thetas: np.ndarray,\n",
        "                       ignore_last: bool = True):\n",
        "    \"\"\"\n",
        "    Take the starting pose and step multiple times to get a roll out from the\n",
        "    starting pose.\n",
        "    \"\"\"\n",
        "    pose_list = [pose_start]\n",
        "    pose_curr = pose_start.copy()\n",
        "\n",
        "    for speed, delta_theta in zip(speeds, delta_thetas):\n",
        "        pose_curr = step_robot_pose(pose_curr, speed, delta_theta)\n",
        "        pose_list.append(pose_curr)\n",
        "\n",
        "    if ignore_last:\n",
        "        pose_list.pop()\n",
        "\n",
        "    return np.array(pose_list)"
      ],
      "metadata": {
        "id": "Lyc30IJYACUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create noise models\n",
        "\n",
        "# For the submission use noise_factor = 1, but you may find it helpful to use\n",
        "# noise_factor = 1e-3 for testing your code.\n",
        "noise_factor = 1\n",
        "\n",
        "# NUMPY VERSIONS\n",
        "# Feel free to change the numbers, just be sure to change them back for the\n",
        "# homework submission.\n",
        "# We assume \"pretty good starting\"\n",
        "PRIOR_NOISE_NUMPY = noise_factor * np.array([0.1, 0.1, np.deg2rad(1)])\n",
        "# 0.3 units in x and y, and 20 degree error in angle, perhaps from wheel encoder\n",
        "ODOMETRY_NOISE_NUMPY = noise_factor * np.array([0.3, 0.3, np.deg2rad(20)])\n",
        "# We assume the LIDAR measurements are a lot cleaner\n",
        "# 0.01 in x and y, and 0.01 degree error in angle\n",
        "MEASUREMENT_NOISE_NUMPY =  noise_factor * np.array([0.01, np.deg2rad(0.01)])\n",
        "\n",
        "# GTSAM versions\n",
        "\n",
        "PRIOR_NOISE = gtsam.noiseModel.Diagonal.Sigmas(noise_factor * PRIOR_NOISE_NUMPY)\n",
        "ODOMETRY_NOISE = gtsam.noiseModel.Diagonal.Sigmas(noise_factor * ODOMETRY_NOISE_NUMPY)\n",
        "MEASUREMENT_NOISE = gtsam.noiseModel.Diagonal.Sigmas(noise_factor * MEASUREMENT_NOISE_NUMPY)"
      ],
      "metadata": {
        "id": "s_jA3Xoz_lzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a dataframe but with the noisy data\n",
        "robot_noisy_df = robot_gt_df.copy()\n",
        "\n",
        "# The random seed is for sanity, to make sure you can run the notebook again\n",
        "# and get the exact same plots.\n",
        "np.random.seed(273)\n",
        "robot_noisy_df[\"speed\"] += np.random.normal(0, ODOMETRY_NOISE_NUMPY[0], n_time_steps)\n",
        "robot_noisy_df[\"dtheta\"] += np.random.normal(0, ODOMETRY_NOISE_NUMPY[-1], n_time_steps)\n",
        "\n",
        "# again, we are using \"near-perfect initialization\" or \"relative to initialization\"\n",
        "# So, no noise is added to the initial pose\n",
        "inital_pose = robot_gt_df[[\"x\", \"y\", \"theta\"]].iloc[0].to_numpy()\n",
        "robot_noisy_df[[\"x\", \"y\", \"theta\"]] = rollout_robot_pose(\n",
        "    inital_pose, robot_noisy_df[\"speed\"], robot_noisy_df[\"dtheta\"])\n",
        "\n",
        "# add noise to the measurements\n",
        "# Loop through the landmarks for range and bearing\n",
        "for l_ind in range(n_landmarks):\n",
        "    robot_gt_df[f\"range_{l_ind}\"] += np.random.normal(0, MEASUREMENT_NOISE_NUMPY[0], n_time_steps)\n",
        "    robot_gt_df[f\"bearing_{l_ind}\"] += np.random.normal(0, MEASUREMENT_NOISE_NUMPY[1], n_time_steps)\n",
        "\n",
        "robot_noisy_df"
      ],
      "metadata": {
        "id": "UhRDDzwVADTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Q4.b-c) Building the factor graph"
      ],
      "metadata": {
        "id": "l65PrRO3ALZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-import here so that you can rerun this cell to debug without rerunning\n",
        "# everything\n",
        "from gtsam.symbol_shorthand import L, X\n",
        "\n",
        "# Create an empty nonlinear factor graph\n",
        "### TODO (Q4.b) ###\n",
        "graph = ...\n",
        "###\n",
        "\n",
        "Xs = [X(i) for i in range(n_time_steps)]\n",
        "Ls = [L(i) for i in range(n_landmarks)]\n",
        "\n",
        "# Add a prior factor at the origin to set the origin of the SLAM problem\n",
        "### TODO (Q4.b) ###\n",
        "# graph.add(...)\n",
        "\n",
        "###\n",
        "\n",
        "# Loop through the noisy data (i.e., `robot_noisy_df`)\n",
        "# In the loop,\n",
        "#    get the relative motion with pose_{i} - pose_{i - 1}\n",
        "#    the measurements are in the noisy data\n",
        "# Don't forget the loop closure constraint\n",
        "### TODO (Q4.c) ####\n",
        "\n",
        "###\n",
        "\n",
        "# Print the factor graph to see all the nodes\n",
        "### TODO (Q4.c) ####\n",
        "\n",
        "###"
      ],
      "metadata": {
        "id": "CLj0me76AdXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Q4.d) Initialize the optimization problem"
      ],
      "metadata": {
        "id": "7lyna7ktCHGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set-up a values data structure for the initial estimate\n",
        "### TODO (Q4.d) ###\n",
        "\n",
        "###\n",
        "\n",
        "# Set the initial poses from the noisy odometry alone\n",
        "# Hint, you already have this in `robot_noisy_df`\n",
        "### TODO (Q4.d) ###\n",
        "\n",
        "###\n",
        "\n",
        "# Sample random values for the initial landmark positions\n",
        "# In reality, you would have to estimate these from odometry,\n",
        "# but to not over-complicate the problem, just use noisy\n",
        "# ground-truth.\n",
        "# In reality, the initialization is very important for the\n",
        "# graph optimization to converge to a good solution!!\n",
        "l_init_vec = [\n",
        "    (-1, -1),\n",
        "    (-1, 1),\n",
        "    (5, 1),\n",
        "    (7, 1),\n",
        "    (10, 1),\n",
        "    (12, -1),\n",
        "    (12, 6),\n",
        "    (10, 4),\n",
        "    (7, 4),\n",
        "    (5, 4),\n",
        "    (-1, 4),\n",
        "    (-1, 6)\n",
        "]\n",
        "\n",
        "for l_ind, L in enumerate(Ls):\n",
        "    l_hat = l_init_vec[l_ind]\n",
        "    point_init = (np.random.normal(l_hat[0], ODOMETRY_NOISE_NUMPY[0]),\n",
        "                  np.random.normal(l_hat[1], ODOMETRY_NOISE_NUMPY[0]))\n",
        "    # Add the initial estimates of the landmarks\n",
        "    ### TODO (Q4.d) ###\n",
        "\n",
        "    ###\n",
        "\n",
        "# Print the initial estimates to verify\n",
        "### TODO (Q4.d) ###\n",
        "\n",
        "###"
      ],
      "metadata": {
        "id": "Yewt7vNDCKCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the initial poses and landmarks.\n",
        "# For example, for poses, the code is\n",
        "# gtsam_plot.plot_pose2(\n",
        "#         fignum: int,\n",
        "#         pose: Pose2,\n",
        "#         axis_length: float = 0.1,\n",
        "#         covariance: np.ndarray = None,\n",
        "#         axis_labels=(\"X axis\", \"Y axis\", \"Z axis\"),\n",
        "# )\n",
        "# We do need covariance for this part. The source code is here:\n",
        "# https://github.com/borglab/gtsam/blob/develop/python/gtsam/utils/plot.py\n",
        "\n",
        "# Don't forget to use axis equals!\n",
        "\n",
        "\n",
        "### TODO (Q4.d) ###\n",
        "\n",
        "###"
      ],
      "metadata": {
        "id": "pqQl_PK3DC9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Q4.e) Graph Optimization"
      ],
      "metadata": {
        "id": "70L52PDnDO2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We are going to optimize with the Levenberg-Marquardt solver.\n",
        "# You can definitely consider other options (e.g., Gauss Newton).\n",
        "# You may be interested in AA 222: Optimization for more about these\n",
        "# methods. Levenberg-Marquardt has a number of configuration\n",
        "# parameters, but we will use the defaults. For your projects, you\n",
        "# might consider tweaking the parameters for tighter convergence.\n",
        "\n",
        "lm_params = gtsam.LevenbergMarquardtParams()\n",
        "\n",
        "# Fill the optimizer with your graph and initial estimates (in that\n",
        "# order).\n",
        "### TODO (Q4.e) ###\n",
        "# optimizer = gtsam.LevenbergMarquardtOptimizer(..., lm_params)\n",
        "# result = optimizer.optimize()\n",
        "###\n",
        "\n",
        "# Print the results\n",
        "### TODO (Q4.e) ###\n",
        "#\n",
        "###"
      ],
      "metadata": {
        "id": "U4XQ8gJTDOWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To understand uncertainty, you need the marginal Gaussian distributions.\n",
        "# gtsam makes this directly accessible with\n",
        "# marginals = gtsam.Marginals(graph, result)\n",
        "# The covariance matrices are in marginals. For example, the covariance\n",
        "# matrix for X(1) (i.e., Xs[0]) is\n",
        "# marginals.marginalCovariance(X(1))\n",
        "\n",
        "# Check that you can print the marginal covariance matrices for both poses\n",
        "# and landmarks\n",
        "### TODO (Q4.e) ###\n",
        "\n",
        "###"
      ],
      "metadata": {
        "id": "Q-4wZHckEdYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now plot the poses and landmarks _with_ covariance ellipses.\n",
        "### TODO (Q4.e) ###\n",
        "\n",
        "###\n",
        "\n",
        "# You may find if helpful to plot line segments connecting poses at\n",
        "# adjacent time steps to understand what is happening.\n",
        "# For a given `pose`, use `pose.translation()` to get the translation\n",
        "# term (i.e., the position)\n",
        "### TODO (Q4.h) ###\n",
        "\n",
        "###"
      ],
      "metadata": {
        "id": "IlJU3cvoFO8q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}